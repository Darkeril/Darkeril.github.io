<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>python爬虫的最佳实践(四)--扒取异步加载内容并存入mongo数据库 | Darkeril&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ps：课前规矩，ps一下。上节我们讲了最简单的爬虫，但是在真实的网络环境下，并不是所有的网页都能用那样的方式抓取，用ajax异步请求数据的网页就没办法用如上方式，那么我们今天就来看看如何抓取异步加载数据的网页。（找网页的时候发现简书的部分页面也是用这种方式加载的，忍了很久还是放过了简书~~）">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫的最佳实践(四)--扒取异步加载内容并存入mongo数据库">
<meta property="og:url" content="http://yoursite.com/2016/05/07/python爬虫的最佳实践-四-扒取异步加载内容并存入mongo数据库/index.html">
<meta property="og:site_name" content="Darkeril's blog">
<meta property="og:description" content="ps：课前规矩，ps一下。上节我们讲了最简单的爬虫，但是在真实的网络环境下，并不是所有的网页都能用那样的方式抓取，用ajax异步请求数据的网页就没办法用如上方式，那么我们今天就来看看如何抓取异步加载数据的网页。（找网页的时候发现简书的部分页面也是用这种方式加载的，忍了很久还是放过了简书~~）">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1957582-15dac9d0885abe51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1957582-2383cfeafc5f4d51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1957582-5612fde88809c820.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1957582-100fbff756edb29f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1957582-8735411f166b7a6e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1957582-b3cd1e541ed57afd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2016-05-07T13:15:36.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬虫的最佳实践(四)--扒取异步加载内容并存入mongo数据库">
<meta name="twitter:description" content="ps：课前规矩，ps一下。上节我们讲了最简单的爬虫，但是在真实的网络环境下，并不是所有的网页都能用那样的方式抓取，用ajax异步请求数据的网页就没办法用如上方式，那么我们今天就来看看如何抓取异步加载数据的网页。（找网页的时候发现简书的部分页面也是用这种方式加载的，忍了很久还是放过了简书~~）">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/1957582-15dac9d0885abe51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
  
    <link rel="alternative" href="/atom.xml" title="Darkeril&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://o6omzqff6.bkt.clouddn.com/icon.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Darkeril</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="#" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="#" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/python/" style="font-size: 10px;">python</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">python的忠实爱好者，QQ：403508380，QQ群：498945822</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Darkeril</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="http://o6omzqff6.bkt.clouddn.com/icon.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Darkeril</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-python爬虫的最佳实践-四-扒取异步加载内容并存入mongo数据库" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/05/07/python爬虫的最佳实践-四-扒取异步加载内容并存入mongo数据库/" class="article-date">
  	<time datetime="2016-05-07T10:21:23.000Z" itemprop="datePublished">2016-05-07</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      python爬虫的最佳实践(四)--扒取异步加载内容并存入mongo数据库
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>ps：课前规矩，ps一下。上节我们讲了最简单的爬虫，但是在真实的网络环境下，并不是所有的网页都能用那样的方式抓取，用ajax异步请求数据的网页就没办法用如上方式，那么我们今天就来看看如何抓取异步加载数据的网页。（找网页的时候发现简书的部分页面也是用这种方式加载的，忍了很久还是放过了简书~~）</p>
<a id="more"></a>
<h2 id="代码预览"><a href="#代码预览" class="headerlink" title="代码预览"></a>代码预览</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#coding:utf-8</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line">import pymongo</span><br><span class="line"></span><br><span class="line">url = &apos;http://www.guokr.com/scientific/&apos;</span><br><span class="line"></span><br><span class="line">def dealData(url):</span><br><span class="line">    client = pymongo.MongoClient(&apos;localhost&apos;, 27017)</span><br><span class="line">    guoke = client[&apos;guoke&apos;]</span><br><span class="line">    guokeData = guoke[&apos;guokeData&apos;]</span><br><span class="line">    web_data = requests.get(url)</span><br><span class="line">    datas = json.loads(web_data.text)</span><br><span class="line">    print datas.keys()</span><br><span class="line">    for data in datas[&apos;result&apos;]:</span><br><span class="line">        guokeData.insert_one(data)</span><br><span class="line"></span><br><span class="line">def start():</span><br><span class="line">    urls = [&apos;http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&amp;limit=20&amp;offset=&#123;&#125;&amp;_=1462252453410&apos;.format(str(i)) for i in range(20, 100, 20)]</span><br><span class="line">    for url in urls:</span><br><span class="line">        dealData(url)</span><br><span class="line"></span><br><span class="line">start()</span><br></pre></td></tr></table></figure>
<h2 id="代码剖析"><a href="#代码剖析" class="headerlink" title="代码剖析"></a>代码剖析</h2><p>细心的同学可能发现了，这和昨天的没什么区别啊0.0。其实不是这样的，这次我们要抓取的数据是果壳网的科学人分页，如果直接通过<code>requests.get(&#39;http://www.guokr.com/scientific/&#39;)</code>你会发现我们要的数据都不在返回网页源代码中，这是因为我们要的数据都是通过ajax的方式异步加载的。那我们应该如何抓取这部分内容呢？首先用浏览器打开我们要抓的网页<br><img src="http://upload-images.jianshu.io/upload_images/1957582-15dac9d0885abe51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="1.png"></p>
<p>随便选择一个地方点开查看元素，细心的同学发现我们这次不用chrome改用火狐了，原因一会告诉大家~</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1957582-2383cfeafc5f4d51.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="2.png"></p>
<p>选择网络标签和XHR分页，然后我们向下滑动鼠标滚轮可以发现一个一个的GET请求被列了出来，这便是ajax异步加载的数据，此时进行观察，如下图：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1957582-5612fde88809c820.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="3.png"></p>
<p>我们可以看到每次请求的url，然后通过观察url变化我们找到了规律，每次的偏移量offset都不一样，代表了我们取出从什么位置取出多少条数据，观察完url规律，我们点击其中一条url，切换到响应分页，如下图所示：<br><img src="http://upload-images.jianshu.io/upload_images/1957582-100fbff756edb29f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4.png"></p>
<p>我们可以看到请求回来的数据格式是json，而且数据结构非常清晰，这也是我选用火狐的原因，我们一眼可以找出我们需要的数据就在result这个key下面。</p>
<p>下面进入我们的代码，start()中拼接url的代码我就不在赘述，我们可以看到这次和上次不同的是引入了两个新库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">import pymongo</span><br></pre></td></tr></table></figure></p>
<p>json库是python自带的json解析库，功能够我们使用的。pymongo是python和mongoDB交互用的库。首先我们来看这段代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">client = pymongo.MongoClient(&apos;localhost&apos;, 27017)</span><br><span class="line">guoke = client[&apos;guoke&apos;]</span><br><span class="line">guokeData = guoke[&apos;guokeData&apos;]</span><br></pre></td></tr></table></figure></p>
<p>PS：一定记得在执行这段代码之前先打开你本地的mongoDB数据库，我在环境配置章节有讲怎么安装mongoDB，不会的同学请参见第二章环境配置。<br>第一句，建立一个pymongo的数据交互客户端，第二句选择名为guoke的database，注意：如果有名为guoke的database则会直接使用已有的，如果没有则会自动建立。第三句选择guoke数据库中名为guokeData的collection。</p>
<p>接下来：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datas = json.loads(web_data.text) </span><br><span class="line">print datas.keys()</span><br></pre></td></tr></table></figure></p>
<p>用json库加载我们取出的数据，然后打印出数据的keys，<br><img src="http://upload-images.jianshu.io/upload_images/1957582-8735411f166b7a6e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="5.png"><br>我们可以看到和我们在火狐浏览器中的数据结构一致，我们需要用的是其中的result字段，刚刚我们通过火狐观察到result是一个list，然后我们遍历result依次存入guokeData这个collection之中。所以，最后一句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">guokeData.insert_one(data)</span><br></pre></td></tr></table></figure></p>
<p>就是给collection中插入一条数据，我个人很喜欢抓取返回格式是json的网站，因为数据格式很规范，可以直接存入mongo中任意取用，操作简单。不用做数据序列化操作，而我们上节那样解析出来的数据要存入数据库就需要做序列化操作。</p>
<p>下来时代码执行完毕后数据库的情况，可以看到我们的数据已经尽数插入数据库<br><img src="http://upload-images.jianshu.io/upload_images/1957582-b3cd1e541ed57afd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="6.png]ACURNVC.png"><br>可以看到很舒服的数据结构。</p>
<p>至此，这一节的内容告一段落，当然，并不是所有的异步加载网页都需要我们去通过观察法获取url然后再采集，这样岂不是会很累，下节将向大家介绍一种非常舒服的方式去做这件事。</p>
<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>惯例，最佳实践的前两步我帮你们做完了，有兴趣的同学可以看一下扩展作业哦。<br>作业：抓取<a href="http://rent.591.com.hk/" target="_blank" rel="external">http://rent.591.com.hk/</a> 这个网站租房的信息，信息都是采用ajax异步加载的方式。而且刚好和我们上节的内容是个强烈对比，不能通过更改url获取分页的数据了，很适合练手~~</p>
<blockquote>
<p>有兴趣的同学可以加群498945822一起交流学习哦~~<br>发现问题的同学欢迎指正，直接说就行，不用留面子，博主脸皮厚！</p>
</blockquote>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/05/07/python爬虫的最佳实践-五-selenium-PhantomJS的简单使用/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          python爬虫的最佳实践(五)--selenium+PhantomJS的简单使用
        
      </div>
    </a>
  
  
    <a href="/2016/05/07/python爬虫的最佳实践-三-真实的网络解析demo/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">python爬虫的最佳实践(三)--真实的网络解析demo</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="python爬虫的最佳实践-四-扒取异步加载内容并存入mongo数据库" data-title="python爬虫的最佳实践(四)--扒取异步加载内容并存入mongo数据库" data-url="http://yoursite.com/2016/05/07/python爬虫的最佳实践-四-扒取异步加载内容并存入mongo数据库/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Darkeril
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>